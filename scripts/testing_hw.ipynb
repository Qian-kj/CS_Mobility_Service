{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylogit as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "from transport_network import approx_shape_centroid, get_haversine_distance, Polygon_Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes={'Detroit': 'mi', 'Boston': 'ma'}\n",
    "state_fips={'Detroit': '26', 'Boston': '25'}\n",
    "NUM_ALTS=8\n",
    "sample_size=5000\n",
    "\n",
    "PUMA_POP_PATH='./cities/'+'Detroit'+'/raw/ACS/population.csv'\n",
    "# https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/\n",
    "PUMS_HH_PATH='./cities/'+'Detroit'+'/raw/PUMS/csv_h'+state_codes['Detroit']+'/ss16h'+state_codes['Detroit']+'.csv'\n",
    "PUMS_POP_PATH='./cities/'+'Detroit'+'/raw/PUMS/csv_p'+state_codes['Detroit']+'/ss16p'+state_codes['Detroit']+'.csv'\n",
    "#        POI_PATH = './cities/'+self.city_folder+'/raw/OSM/poi.geojson'\n",
    "PUMA_TO_POW_PUMA_PATH='./puma_to_pow_puma.csv'\n",
    "PUMA_SHAPE_PATH = './cities/'+'Detroit'+'/raw/pumas.geojson'\n",
    "PUMAS_INCLUDED_PATH = './cities/'+'Detroit'+'/raw/pumas_included.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh=pd.read_csv(PUMS_HH_PATH)\n",
    "pop = pd.read_csv(PUMS_POP_PATH)\n",
    "hh['PUMA']=hh.apply(lambda row: str(int(row['PUMA'])).zfill(5), axis=1)\n",
    "pop['PUMA']=pop.apply(lambda row: str(int(row['PUMA'])).zfill(5), axis=1)\n",
    "pop['POWPUMA']=pop.apply(lambda row: str(int(row['POWPUMA'])).zfill(5) \n",
    "                        if not np.isnan(row['POWPUMA']) else 'NaN', axis=1)\n",
    "\n",
    "#        all_PUMAs=list(set(hh['PUMA']))\n",
    "pumas_included=json.load(open(PUMAS_INCLUDED_PATH))                                         # For the whole MI\n",
    "pumas_shape=json.load(open(PUMA_SHAPE_PATH))\n",
    "pumas_order=[f['properties']['PUMACE10'] for f in pumas_shape['features']]\n",
    "            \n",
    "puma_pop = pd.read_csv(PUMA_POP_PATH)\n",
    "puma_pop = puma_pop.loc[puma_pop['STATE']==int(state_fips['Detroit'])]\n",
    "puma_pop['PUMA']=puma_pop.apply(lambda row: str(row['PUMA']).zfill(5), axis=1)\n",
    "puma_pop=puma_pop.set_index('PUMA')\n",
    "\n",
    "\n",
    "# identify recent movers and vacant houses                                            \n",
    "hh_vacant_for_rent=hh[(hh['VACS']==1) & (hh['PUMA'].isin(pumas_included['puma']))].copy()          \n",
    "hh_rented=hh[(hh['TEN']==3) & (hh['PUMA'].isin(pumas_included['puma']))].copy()                                                      \n",
    "renters_recent_move=hh_rented[hh_rented['MV']==1].copy()    \n",
    "\n",
    "# get the area of each PUMA\n",
    "puma_land_sqm=dict(zip(puma_pop.index, puma_pop['AREALAND'].astype('int64')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between each puma and each pow-puma\n",
    "pow_puma_df=pd.read_csv(PUMA_TO_POW_PUMA_PATH, skiprows=1, header=1)\n",
    "pow_puma_df_state=pow_puma_df.loc[pow_puma_df[\n",
    "        'State of Residence (ST)']==state_fips['Detroit']].copy()\n",
    "pow_puma_df_state['POW_PUMA']=pow_puma_df_state.apply(\n",
    "        lambda row: str(int(row['PWPUMA00 or MIGPUMA1'])).zfill(5), axis=1)\n",
    "pow_puma_df_state['PUMA']=pow_puma_df_state.apply(\n",
    "        lambda row: str(int(row['PUMA'])).zfill(5), axis=1)\n",
    "all_pow_pumas=set(pow_puma_df_state['POW_PUMA'])\n",
    "pow_puma_to_puma={}\n",
    "for p in all_pow_pumas:\n",
    "    pow_puma_to_puma[p]=list(pow_puma_df_state.loc[\n",
    "            pow_puma_df_state['POW_PUMA']==p, 'PUMA'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the centroid of each puma\n",
    "puma_centroids={}\n",
    "pow_puma_centroids={}\n",
    "for puma in set(pow_puma_df_state['PUMA']):\n",
    "    centr=approx_shape_centroid(pumas_shape['features'][pumas_order.index(puma)]['geometry'])\n",
    "    puma_centroids[puma]=centr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the centroid of each pow-puma\n",
    "all_pow_pumas=set(pow_puma_df_state['POW_PUMA'])\n",
    "\n",
    "for pow_puma in all_pow_pumas:\n",
    "    pumas=pow_puma_to_puma[pow_puma]\n",
    "    puma_centr=[puma_centroids[puma] for puma in pumas]\n",
    "    # TODO, shold be weighted by area- ok if similar size\n",
    "    pow_puma_centroids[pow_puma]=[np.mean([pc[0] for pc in puma_centr]),\n",
    "                                    np.mean([pc[1] for pc in puma_centr])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance between puma and pow-puma\n",
    "dist_mat={}\n",
    "for puma in puma_centroids:\n",
    "    dist_mat[puma]={}\n",
    "    for pow_puma in pow_puma_centroids:\n",
    "        dist = get_haversine_distance(\n",
    "                puma_centroids[puma], pow_puma_centroids[pow_puma])\n",
    "        # external distance\n",
    "        if dist > 0:\n",
    "            dist_mat[puma][pow_puma] = dist\n",
    "        # inner distance\n",
    "        else:\n",
    "            dist_mat[puma][pow_puma] = np.sqrt(puma_land_sqm[puma] / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the PUMA aggregate data data frame\n",
    "median_income_by_puma=hh.groupby('PUMA')['HINCP'].median()\n",
    "#TODO: get more zonal attributes such as access to employment, amenities etc.\n",
    "\n",
    "puma_obj=[{'PUMA':puma,\n",
    "            'med_income':median_income_by_puma.loc[puma],\n",
    "            'puma_pop_per_sqm':float(puma_pop.loc[puma]['POP100'])/puma_land_sqm[puma]\n",
    "            } for puma in pumas_included['puma']]\n",
    "\n",
    "puma_attr_df=pd.DataFrame(puma_obj)\n",
    "puma_attr_df=puma_attr_df.set_index('PUMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features at property level\n",
    "# normalise rent stratifying by bedroom number\n",
    "renters_recent_move.loc[renters_recent_move['BDSP']>2, 'BDSP']=3            # change [the number of bedroom] >2 to 3\n",
    "renters_recent_move.loc[renters_recent_move['BDSP']<1, 'BDSP']=1            # change [the number of bedroom] <1 to 1\n",
    "hh_vacant_for_rent.loc[hh_vacant_for_rent['BDSP']>2, 'BDSP']=3          \n",
    "hh_vacant_for_rent.loc[hh_vacant_for_rent['BDSP']<1, 'BDSP']=1\n",
    "rent_mean={}\n",
    "rent_std={}\n",
    "for beds in range(1,4):\n",
    "    rent_mean[beds]=renters_recent_move.loc[renters_recent_move['BDSP']==beds, 'RNTP'].mean()\n",
    "    rent_std[beds]=renters_recent_move.loc[renters_recent_move['BDSP']==beds, 'RNTP'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [renters_recent_move, hh_vacant_for_rent]:\n",
    "    df['norm_rent']=df.apply(\n",
    "        lambda row: (row['RNTP']-rent_mean[row['BDSP']])/rent_std[row['BDSP']], axis=1)\n",
    "    # Age of building\n",
    "    df['built_since_jan2010']=df.apply(lambda row: row['YBL']>=14, axis=1)\n",
    "    df['puma_pop_per_sqmeter']=df.apply(lambda row: puma_attr_df.loc[row['PUMA']]['puma_pop_per_sqm'], axis=1)\n",
    "    df['med_income']=df.apply(lambda row: puma_attr_df.loc[row['PUMA']]['med_income'], axis=1)  \n",
    "all_rooms_available = pd.concat([hh_vacant_for_rent, renters_recent_move], axis=0) \n",
    "median_norm_rent = all_rooms_available.groupby('PUMA')['norm_rent'].median()\n",
    "puma_attr_df['media_norm_rent'] =  puma_attr_df.apply(lambda row: median_norm_rent[row.name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of avaiable housing units in each PUMA\n",
    "num_available_houses_in_puma = hh_vacant_for_rent.groupby('PUMA')['SERIALNO'].count()\n",
    "pumas_included_pd = pd.Series(0, index = pumas_included['puma'])\n",
    "num_available_houses_in_puma = (num_available_houses_in_puma + pumas_included_pd).fillna(0)\n",
    "puma_attr_df['num_houses'] = puma_attr_df.apply(lambda row: num_available_houses_in_puma[row.name], axis=1)\n",
    "\n",
    "renters_recent_move=renters_recent_move[['SERIALNO', 'PUMA','HINCP',  'norm_rent', 'RNTP', 'built_since_jan2010', 'puma_pop_per_sqmeter', 'med_income', 'BDSP', 'NP']]\n",
    "hh_vacant_for_rent=hh_vacant_for_rent[['PUMA', 'HINCP', 'norm_rent', 'RNTP','built_since_jan2010', 'puma_pop_per_sqmeter', 'med_income', 'BDSP']]\n",
    "    \n",
    "rent_normalisation={\"mean\": rent_mean, \"std\": rent_std}\n",
    "\n",
    "home_loc_mnl = {'home_loc_mnl_PUMAs': {}, 'home_loc_mnl_hh': {}}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[info] Preparing long data for PUMA-level choice.\n",
      "[info] Long data for PUMA-level choice finished. Elapsed time: 0.0575108528137207 seconds\n"
     ]
    }
   ],
   "source": [
    "# Model Estimation\n",
    "# First stage: choice model on PUMA level\n",
    "# =============================================================================\n",
    "long_data_PUMA = pd.DataFrame()\n",
    "print('\\n\\n[info] Preparing long data for PUMA-level choice.')\n",
    "time1 = time.time()\n",
    "numPUMAs = puma_attr_df.shape[0]\n",
    "ind = 0\n",
    "for ind_actual, row_actual in renters_recent_move.iterrows():\n",
    "    if ind >= sample_size:\n",
    "        break\n",
    "householdID = row_actual['SERIALNO']\n",
    "places_of_work = set(pop.loc[pop['SERIALNO']==householdID, 'POWPUMA'])\n",
    "places_of_work = [x for x in places_of_work if x in all_pow_pumas]\n",
    "if len(places_of_work):\n",
    "    this_sample_puma_attr_df = puma_attr_df.copy()\n",
    "    this_sample_puma_attr_df['custom_id'] = ind_actual * np.ones(numPUMAs, dtype=np.int8)\n",
    "    this_sample_puma_attr_df['choice_id'] = list(puma_attr_df.index)\n",
    "    this_sample_puma_attr_df['choice'] = np.zeros(numPUMAs)\n",
    "    this_sample_puma_attr_df['hh_income'] = row_actual['HINCP']\n",
    "    this_sample_puma_attr_df.loc[this_sample_puma_attr_df['choice_id']==row_actual['PUMA'], 'choice'] = 1\n",
    "    this_sample_puma_attr_df['work_dist'] = [np.mean([dist_mat[puma][pow_puma] \n",
    "                                            for pow_puma in places_of_work]) for puma in list(puma_attr_df.index)]\n",
    "    long_data_PUMA = pd.concat([long_data_PUMA, this_sample_puma_attr_df], axis=0)\n",
    "    ind += 1\n",
    "\n",
    "long_data_PUMA['income_disparity']=long_data_PUMA.apply(lambda row: np.abs(row['hh_income']-row['med_income']), axis=1)\n",
    "time2 = time.time()\n",
    "print('[info] Long data for PUMA-level choice finished. Elapsed time: {} seconds'.format(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data_PUMA.to_csv('./cities/'+'Detroit'+'/clean/logit_data_long_form/logit_data_PUMA.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[info] Fitting Upper Level Model\n",
      "Log-likelihood at zero: -3.4965\n",
      "Initial Log-likelihood: -3.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -0.0000\n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                    1\n",
      "Model:             Multinomial Logit Model   Df Residuals:                       -4\n",
      "Method:                                MLE   Df Model:                            5\n",
      "Date:                     Sat, 26 Aug 2023   Pseudo R-squ.:                   1.000\n",
      "Time:                             12:12:16   Pseudo R-bar-squ.:              -0.430\n",
      "AIC:                                10.000   Log-Likelihood:                 -0.000\n",
      "BIC:                                 0.000   LL-Null:                        -3.497\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "puma_pop_per_sqm  1.981e+05   1.92e+10   1.03e-05      1.000   -3.77e+10    3.77e+10\n",
      "income_disparity     0.0020    542.660   3.62e-06      1.000   -1063.593    1063.597\n",
      "work_dist            0.0064   1369.762   4.65e-06      1.000   -2684.678    2684.691\n",
      "media_norm_rent    -33.7826   2.16e+06  -1.56e-05      1.000   -4.24e+06    4.24e+06\n",
      "num_houses           4.7390   1.03e+05   4.59e-05      1.000   -2.02e+05    2.02e+05\n",
      "====================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jiang\\anaconda3\\envs\\cusplondon\\lib\\site-packages\\scipy\\optimize\\_minimize.py:523: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n",
      "c:\\Users\\Jiang\\anaconda3\\envs\\cusplondon\\lib\\site-packages\\pylogit\\base_multinomial_cm_v2.py:1259: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self._store_inferential_results(np.sqrt(np.diag(self.robust_cov)),\n"
     ]
    }
   ],
   "source": [
    "choiceModelPUMA_spec = OrderedDict()\n",
    "choiceModelPUMA_names = OrderedDict()\n",
    "choiceModelPUMAsRegressors = ['puma_pop_per_sqm', 'income_disparity', 'work_dist', 'media_norm_rent', 'num_houses'] + [x for x in list(long_data_PUMA.columns) if x.endswith('_den')]\n",
    "for var in choiceModelPUMAsRegressors:\n",
    "    choiceModelPUMA_spec[var] = [list(set(long_data_PUMA['choice_id']))]\n",
    "    choiceModelPUMA_names[var] = [var]\n",
    "\n",
    "home_loc_mnl_PUMAs = pl.create_choice_model(data=long_data_PUMA,\n",
    "                                    alt_id_col='choice_id',\n",
    "                                    obs_id_col='custom_id',\n",
    "                                    choice_col='choice',\n",
    "                                    specification=choiceModelPUMA_spec,\n",
    "                                    model_type=\"MNL\",\n",
    "                                    names=choiceModelPUMA_names)\n",
    "print('\\n[info] Fitting Upper Level Model')\n",
    "numCoef=sum([len(choiceModelPUMA_spec[s]) for s in choiceModelPUMA_spec])\n",
    "\n",
    "# pylogit may encounter memory error in calculating Hessiann matrix for S.E. in this model, if so, switch to noHessian approach and only do point estimation.\n",
    "try:\n",
    "    home_loc_mnl_PUMAs.fit_mle(np.zeros(numCoef))\n",
    "    print(home_loc_mnl_PUMAs.get_statsmodels_summary())\n",
    "    home_loc_mnl['home_loc_mnl_PUMAs'] = {'just_point': False, 'model': home_loc_mnl_PUMAs}\n",
    "except:\n",
    "    home_loc_mnl_PUMAs_result = home_loc_mnl_PUMAs.fit_mle(np.zeros(numCoef), just_point=True)\n",
    "    params = home_loc_mnl_PUMAs_result['x']\n",
    "    print('\\nLogit model parameters:\\n---------------------------')\n",
    "    for varname, para in zip(home_loc_mnl_PUMAs.ind_var_names, params):\n",
    "        print('{}: {:4.6f}'.format(varname, para))\n",
    "    home_loc_mnl['home_loc_mnl_PUMAs'] = {'just_point': True, 'model': home_loc_mnl_PUMAs, 'params': params, 'var_names': home_loc_mnl_PUMAs.ind_var_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cusplondon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
